---
title:  "Fully convolutional networks for semantic segmentation review"
last_modified_at: 2020-09-12 00:00:00 -0400
categories: 
  - Segmentation paper
tags:
  - update
toc: true
toc_label: "Getting Started"
---

# Fully convolutional networks for semantic segmentation
> Long, Jonathan, Evan Shelhamer, and Trevor Darrell. "Fully convolutional networks for semantic segmentation." Proceedings of the IEEE conference on computer vision and pattern recognition. 2015.

## Abstract
 
* 기존의 SOTA를 뛰어넘는 end-to-end, pixels-to-pixels로 학습이 가능한 convolutional networks를 보여줌

* Fully convolutional network로 임의의 사이즈의 input을 처리할 수 있고, 효율적인 inference와 학습을 가능하게 함

* Classification networks(AlexNet,VGG,GoogleNet)을 fully convolutional networks에 적용시키고, 학습된 representations을 segmentation task에 알맞게 fine-tuning 함

* 정확하고 상세한 segmentations 결과를 생성하기 위해, 깊은 layers에서의 semantic 정보(coarse layer)와 얕은 layers에서의 appearance 정보(fine layer)를 결합

* fully convolutional network는 PASCAL VOC, NYUDv2, SIFT Flow에서 SOTA 성능을 달성했고, inference 속도도 빠름

## Introduction

* CNN을 통해 많은 recognition tasks에 발전이 있었음

> bounding box object detection, part and key point prediction, local correspondence

* 기존의 semantic segmentation 방식들은 convnets을 사용하였으나, 이는 단점이 존재함 

* * *

### FCN : fully convolutional network

* 기존의 SOTA 성능을 뛰어넘고, end-to-end, pixels-to-pixels로 학습이 가능

* 최초로 FCN을 end-to-end로 pixel 단위 예측에 적용하고, supervised pre-training을 사용

* 임의의 사이즈를 가진 inputs으로부터 dense outputs을 예측

* inference와 학습이 전체 이미지에 대하여 한번 수행 (dense feedforward computation and backpropagation)

* network 내부 upsampling layers는 subsampling pooling으로 pixel 단위 예측과 학습을 가능하게 함

* * *

### 기존 방식들 vs FCN

* FCNs은 기존의 patchwise training과 다르게, 복잡한 선,후처리가 필요하지 않음

> 기존 방식은 효율적이지 못함

* 제안한 방식은 기존의 classification networks를 fully convolutional network로 수정하고, fine-tuning하여 사용

> 기존의 방식들은 pre-training 없이 작은 convnets을 적용함

* * *

* global information은 의미정보를 담고 있고, local information은 위치정보를 담고 있음

> deep feature의 계층들에는 위치정보와 의미정보가 공동으로 encoding

* skip 구조를 통해 deep features와 shallow features를 결합시킴

> deep,coarse,semantics / shallow,fine,appearance

<img src="/assets/img/FCN/fig3.PNG" width="100%" height="100%" title="70px" alt="memoryblock">

## Fully convolutional networks

### 3.1 Adapting classifiers for dense prediction

* 기존의 일반적인 recognition networks(LeNet, AlexNet)는 input size가 고정되어 있고, 공간정보가 없는 outputs 생성

> fully connected layers에 의해 dimension이 고정되고, 공간 좌표를 버림

* 위와 같은 문제점을 해결하기 위해, fully connected layers를 전체 input regions을 커버하는 kernels을 갖는 convolutions으로 간주하고 대체함

> 임의의 사이즈를 갖는 input을 다룰 수 있고, classification maps을 생성함

<img src="/assets/img/FCN/fig2.PNG" width="60%" height="60%" title="70px" alt="memoryblock">

* FCN은 높은 계산 효율성을 가짐

### 3.2 Shift-and-stitch is filter rarefaction

* OverFeat에서 소개된 Shift-and-stitch trick은 보간법 없이 coarse outputs에서 dense predictions을 생성하는 방법

* Convnet의 layers나 filters의 stride를 변경하는 것만으로 shift-and-stitch trick과 동일한 output을 생성할 수 있음

> trick을 사용하는 것보다 효과적임

### 3.3 Upsampling is backwards strided convolution

* coarse outputs을 dense pixels로 연결시키는 또 다른 방법은 보간법 (ex, bilinear interpolation)

* factor f로 upsampling을 하는 것은 convolution을 1/f stride로 수행하는 것과 동일함

> 또는 stride가 f인 convolution을 반대로 수행하는 것 (deconvolution)

* 보간법을 이용하지 않고 deconvolution layer를 이용하여 upsampling을 수행하면 end-to-end로 학습이 가능함

> bilinear interpolation은 학습되지 않고 고정된 연산을 수행함

### 3.4 Patchwise training is loss sampling

* patchwise training에 대한 실험을 진행하였으나, 이는 전체 이미지에 대하여 학습을 진행하는 것보다 계산 효율성이 좋지 못함 

* 전체 이미지 학습이 효과적이고 효율적임

## Segmentation Architecture

### 4.1 From classifier to dense FCN

* 총 3개의 classification networks를 사용 : AlexNet, VGG, GoogleNet 

* classifier -> FCN

> 최종 classifier layer를 제거하고 모든 fully connected layers를 convolutions으로 변경

> PASCAL VOC classes를 예측하기 위해 channel dimension을 21로 변경시키는 1x1 convolution 추가

> 이후에 deconvolution layer를 통해 pixel-dense outputs 생성

* 실험 결과

<img src="/assets/img/FCN/T1.PNG" width="60%" height="60%" title="70px" alt="memoryblock">

> GoogleNet이 좋지 않은 성능을 보임

### 4.2 Combining what and where

### 4.3 Experimental framework


