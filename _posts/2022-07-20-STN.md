---
title: "[Paper Review] Spatial transformer networks"
last_modified_at: 2022-07-20 00:00:00 -0400
categories: 
  - Deep learning paper
tags:
  - update
toc: true
use_math: true
toc_label: "Getting Started"
---

# Spatial transformer networks
> Jaderberg, Max, Karen Simonyan, and Andrew Zisserman. "Spatial transformer networks." Advances in neural information processing systems 28 (2015).

## Abstract

CNN은 매우 강력하지만, 계산 및 파라미터 효율적인 방식으로 입력 데이터에 공간적으로 불변하는 능력이 부족하여 여전히 제한적임

> 공간적 변형에 취약한 CNN

```
invariance는 불변성이라는 뜻으로 함수의 입력이 바뀌어도 출력은 그대로 유지되어 바뀌지 않는다는 뜻이고, 
공간적으로 변형된 입력 데이터에 대해서도 동일한 결과값을 내는 것을 의미

참고 자료 : https://seoilgun.medium.com/cnn%EC%9D%98-stationarity%EC%99%80-locality-610166700979
```

논문에서는 네트워크 내에서 데이터의 공간적 조정을 명시적으로 허용하는 학습 가능한 Spatial Transformer 모듈을 제안

> Spatial Transformer 모듈은 미분이 가능하고, 기존의 CNN 구조에 삽입이 가능

> 최적화 과정에서 추가적인 학습 지도나 수정없이 feature map 자체에 맞추어 feature map을 공간적으로 변형시키는 기능을 제공

spatial transformers의 사용이 공간적 변형(translation, scale, rotation, more generic warping)에 대한 invariance을 학습할 수 있게 하는 것을 실험으로 확인했고, SOTA 성능 달성

## Introduction

최근, CNN(fast, scalable, end-to-end)의 등장으로 컴퓨터 비전에 큰 발전이 있었음

classification, localisation, semantic segmentation, action recognition 등 다양한 분야에서 CNN 기반 모델이 SOTA를 달성하는 것을 볼 수 있음

* * *

이미지를 추론할 때 중요한 능력은 texture와 shape으로부터 object pose와 part deformation을 구분하는 것임

> object pose : 객체가 속해있는 부분이 어디인지 판별 (객체의 모양)

CNN에서 local max-pooling layer의 도입이 네트워크가 features의 위치에 다소 공간적으로 불변하도록 하여 추론 능력에 도움이 됨

하지만, max-pooling은 작은 공간(2x2 pixels)에 대해서 적용하기 때문에 공간 불변성은 max-pooling과 convolution layer를 깊게 쌓은 구조에서만 실현됨

> 이러한 사전 정의된 pooling mechanism이 CNN의 한계점 (고정적인 연산)

* * *

본 논문에서는 neural network에 공간적 변형 능력을 제공하기 위한 Spatial Transformer module 소개

- Spatial Transformer

  추가적인 지도학습 없이 task를 위해 학습하는 과정에서 학습된 적절한 행동에 의해 입력 데이터에 따라 컨디션 됨
  
  receptive field가 고정적이고 지역적인 pooling layer와 달리, image or feature map을 공간적으로 변형할 수 있는 동적인 메커니즘
  
  > 입력 데이터에 따라 다르게 변형됨
  
  변형이 전체 feature map에 대해 수행되고 (non-locally), scaling, cropping, rotations, non-rigid 변형을 포함할 수 있음
  
  모델에 삽입하고 표준적인 back-propagation으로 학습이 가능 (end-to-end 학습)
  
- Spatial Transformer module의 효과

  1. task를 수행하기 위해 가장 중요한 영역을 선택할 수 있게 함 (attention)
  
  2. 다음 layer에서 더 쉽게 인식할 수 있는 형태로 변형하여 전달

- Spatial transformers은 다양한 task에 적용할 수 있음

  - image classification

    <img src="/assets/img/STN/fig1.JPG" width="80%" height="80%">
    
    숫자 이미지 분류(MNIST)에서 숫자의 위치와 사이즈는 데이터 샘플마다 매우 다양함
    
    Spatial transformers는 적절한 영역을 크롭하고 스케일을 조정하고, 이는 classification task를 더 쉽게 만들어주며 좋은 성능으로 이어짐
    
  - co-localisation
  
    동일한 클래스의 다른 instances가 포함되어 있는 이미지들이 주어졌을 때, spatial transformer가 각 이미지에서 instance들을 localisation 하는데 사용될 수 있음
  
  - spatial attention

    attention mechanism을 필요로 하는 task에 사용될 수 있고, 이는 강화학습 없이 backpropagation 만으로 더 유연하게 학습될 수 있음
    
## Spatial Trnasformers

<img src="/assets/img/STN/fig2.JPG" width="100%" height="100%">
