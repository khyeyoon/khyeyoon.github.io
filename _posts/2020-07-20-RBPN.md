---
title:  "Recurrent back-projection network for video super-resolution review"
last_modified_at: 2020-07-20 00:00:00 -0400
categories: 
  - Video Super-Resolution paper
  - "2019"
tags:
  - update
toc: true
toc_label: "Getting Started"
---

# Recurrent back-projection network for video super-resolution
> Haris, Muhammad, Gregory Shakhnarovich, and Norimichi Ukita. "Recurrent back-projection network for video super-resolution." Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2019.

**Abstract**

* recurrent encoder-decoder module을 사용하여 연속적인 video frames에서 spatial context와 temporal context를 통합시킴

> multi-frame 정보와 target frame의 single frame super-resolution path를 융합 (MISR+SISR)

* 이전 연구들은 frames이 쌓이거나 warping하면서 함께 풀링되었으나, RBPN은 모든 context frame을 분리된 정보로 처리

> 이러한 정보들은 반복적인 refinement framework로 결합됨 (MISR의 back-projection에서 영감)

> 이는 명시적으로 프레임을 정렬하는 것이 아니라 target에 대해 추정된 inter-frame motion을 명시적으로 나타냄으로써 도움이 됨(??)

* 새로운 video super-resolution benchmark 제안

> 큰 규모의 평가를 진행하며 다른 motion regimes의 videos를 고려함

**Introdection**

* SR의 3가지 분야 : SISR, MISR, VSR

* Single Image Super-Resolution

> video SR을 SISR 처럼 독립적으로 처리하면 다른 frames에서 얻을 수 있는 정보(missing details)를 버림

* Multi-frame Image Super-Resolution

> 다른 frames에서 이용 가능한 정보(missing details)를 target frame을 복원시키기 위해 융합시킴

> frames은 독립적으로 alignment를 맞추기 때문에 temporal 정보를 이용하기 어려움 (difficulty in the precise alignment)

* Video Super-Resolution

> 1) The frame concatenation approach : 네트워크에서 많은 frames이 동시에 처리되면서 학습에 어려움이 있음

> 2) RNNs : 작고 큰 변화를 공동으로 modelling 하기 어려움

* * *

* DBPN : Deep Back-Projection Networks

> MISR에서의 "back-projection"에서 영감을 얻음

> > Back-projection : target image와 그에 해당하는 image set 사이의 error인 residual image를 반복적으로 계산 (residuals은 resolution을 향상시키기 위해 target image로 back-projection)

> > multiple residuals은 target frame과 다른 frames 간 작고 큰 변화를 독립적으로 representing 할 수 있음 (기존 RNNs 한계를 극복)

> - back-projection을 Deep SISR(오직 하나의 LR image로 HR 생성)로 확장

> - multiple up- and down-sampling layers를 통해 반복적으로 조정(refine)하면서 high-resolution feature map 생성

> - VSR을 위해 MISR back-projection과 DBPN의 장점을 통합시킴

> DBPN architecture

<img src="/assets/img/RBPN/DBPN.PNG" width="80%" height="80%" title="70px" alt="memoryblock">

> - 다른 video frames을 original MISR back-projection에서 LR images 처럼 사용

> -  missing detials을 representing 하는 HR feature maps을 up- and down- sampling 과정들에 의해 반복적으로 정제(refine)하는 아이디어를 활용 (SR quality 향상을 위해)

* Contributions

1) Integrating SISR and MISR in a unified VSR framework

> SISR과 MISR은 다른 sources에서 missing details을 추출

> > Iterative SISR (DBPN) : target frame의 details을 나타내는 다양한 feature maps 추출

> > MISR : 다른 frames로부터 다양한 feature maps의 집합을 제공

> 다른 sources는 RNN을 통해 temporal 순서로 반복적으로 update

2) Back-projection modules for RBPN

> back-projection을 통해 SISR와 MISR paths에서 추출된 details을 통합시키기 위해 기존의 encoder-decoder mechanism을 발전시킴

> <img src="/assets/img/RBPN/fig1d.PNG" width="50%" height="50%" title="70px" alt="memoryblock">

> network는 모든 context가 개별적으로 계산되기 때문에 large gap을 이해할 수 있음 (I_t와 I_t-n 사이의 gap??)

> > 이전의 연구는 공동으로 계산되었음

> 분리된 context는 RBPN에서 중요한 역할

3) Extended evaluation protocol

> 기존의 standard dataset(Vid4와 SPMCS, 많은 motion을 담고 있지 못함)에 추가적으로 Vimeo-90k를 사용하여 평가

**Relate Work**

* 2.3 Deep Video Super-Resolution

(a) Temporal Concatenation

> input frames을 함께 concatenation 하면서 sequence에 대한 다양한 motion regimes을 나타내지 못함 (motion 정보를 다루지 못함)

<img src="/assets/img/RBPN/fig1.a.PNG" width="50%" height="50%" title="70px" alt="memoryblock">

(b) Temporal Aggregation

> dynamic motion problem을 해결하기 위해, 다양한 motion regimes을 다루는 multiple SR inferences 제안

> 마지막 layer에서 모든 branch의 output을 concatenation함

> 여전히 많은 input frames을 concatenation -> difficulty in global optimization

<img src="/assets/img/RBPN/fig1.b.PNG" width="50%" height="50%" title="70px" alt="memoryblock">

(c) RNNs 

> [13]에서 처음으로 제안되었지만, 작은 network capacity를 가졌고 frame align step이 없었음

> 더 나아가 motion compensation module과 convLSTM layer를 사용한 방식이 제안됨 [30]

> 최근에는 이전 예측 frame(HR)을 다음 frame 예측에 사용하는 효율적인 many-to-many RNN 제안 [27]

> 기존 RNN 한계 : 반복적인 feedback connection은 이웃 frames 간 temporal smoothness를 이용하지만, 모든 frames에서 작고 큰 변화를 공동으로 modelling하기 어려움

<img src="/assets/img/RBPN/fig1.c.PNG" width="50%" height="50%" title="70px" alt="memoryblock">

**Recurrent Back-Projection Networks**

* 3.1 Network Architecture

<img src="/assets/img/RBPN/fig2.PNG" width="100%" height="100%" title="70px" alt="memoryblock">

* * *

1) Initial feature extraction

> projection module에 들어가기 전에 I_t를 LR feature tensor L_t로 mapping

> 모든 이웃 frame(I_t-1 ~ I_t-n)에 대해 미리 계산된 dense motion flow map F_t-k(I_t-k와 I_t 사이의 flow map)을 I_t-k, I_t와 concatenation

> motion flow map의 효과 : projection module이 frame 사이의 missing details을 추출하는 것을 도움

* * * 

2) Multiple Projections

> SISR과 MISR paths를 통합시키면서 target frame에서 missing details을 추출하여 refined HR feature tensor 생성

* * *

3) Reconstruction

> 모든 frame에 대한 HR features를 concatenation하여 reconstruction module로 넣어주어 최종 SR output을 얻음

> 하나의 convolutional layer로 이루어짐

* * *

* 3.3 Multiple Projection

> RBPN에서 multiple projection stage는 encoder-decoder modules의 반복적인 chain 구조를 이용

> <img src="/assets/img/RBPN/fig3.PNG" width="50%" height="50%" title="70px" alt="memoryblock">

> encoder : 특정 이웃 frame에 대한 projection에서 HR feature를 생성 

> decoder : 각각의 HR feature를 다음 encoder module의 input으로 넣기 위해 decoding

<img src="/assets/img/RBPN/eq12.PNG" width="50%" height="50%" title="70px" alt="memoryblock">

<img src="/assets/img/RBPN/fig4.PNG" width="50%" height="50%" title="70px" alt="memoryblock">

> The encoder module

<img src="/assets/img/RBPN/encoder.PNG" width="50%" height="50%" title="70px" alt="memoryblock">

* 3.3 Interpretation

<img src="/assets/img/RBPN/fig5.PNG" width="100%" height="100%" title="70px" alt="memoryblock">

> 3-frame video를 위한 RBPN pipeline

















