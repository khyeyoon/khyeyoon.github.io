---
title: "[Paper Review] Language models are few-shot learners"
last_modified_at: 2022-08-13 00:00:00 -0400
categories: 
  - nlp paper
tags:
  - update
toc: true
use_math: true
toc_label: "Getting Started"
---

# Language models are few-shot learners
> Brown, Tom, et al. "Language models are few-shot learners." Advances in neural information processing systems 33 (2020): 1877-1901.

# Abstract

최근 연구들은 대규모 텍스트를 이용하여 모델을 사전 학습시킨 후, 특정 task에 맞추어 fine-tuning 하는 방식으로 다양한 NLP task와 벤치마크에서 상당한 성능 향상을 이루었습니다.

하지만, 일반적으로 이러한 방식의 모델(task-agnostic)은 fine-tuning을 위해 task 별로 수천, 수만 개의 데이터가 필요하다는 단점이 있습니다.

이와 대조적으로 실제 사람은 단지 몇개의 샘플이나 설명만으로 새로운 언어 task를 수행할 수 있습니다.

논문에서는 언어 모델의 사이즈를 증가시키는 것이 task-agnostic, few-shot 성능을 크게 향상시키는 것을 확인하였고, 일부 task에서는 fine-tuning 방식의 SOTA의 성능과도 비교할만한
결과를 보여줬습니다.

구체적으로, GPT-3는 autoregressive language model로 1750억개의 파라미터를 가지고 있고, 이를 few-shot 환경에서 성능을 테스트하였습니다.

> 기존의 non-sparse language model의 10배 정도 크기

모든 task에서 GPT-3는 어떠한 파라미터 업데이트나 fine-tuning을 수행하지 않았고, 단지 텍스트를 이용한 상호작용만으로 모델이 task를 수행할 수 있도록 하였습니다.

GPT-3는 번역, 질의 응답, cloze task 등 다양한 NLP task에서 강력한 성능을 달성하였고, 이외에도 즉석 추론이나 도메인 적응이 필요한 task에서도 좋은 성능을 보였습니다.

또한, 논문에서는 GPT-3의 few-shot learning에서 잘동작하지 않는 일부 데이터셋과 대규모 웹 텍스트에 대한 학습 관련 문제에 직면한 일부 데이터셋을 확인하였습니다.

최종적으로, GPT-3가 사람이 판별하기 어려운 정도로 실제적인 뉴스 기사를 생성해낼 수 있는 것을 확인하였고, 이러한 발견과 GPT-3의 사회적 영향에 대해 논의하였습니다.

# Introduction

최근 NLP 시스템은 사전 학습된 language representations을 이용하고 있고, downstream transfer를 위해 점점 유연하고 task에 구애받지 않는 방식(task-agnostic)으로 발전하고 있습니다.

1. 단일 레이어로 학습된 단어 벡터 representations

2. 여러 층의 레이어로 구성된 RNN으로 학습된 representations, contextual state 
    
3. 사전 학습된 recurrent or transformer language models

    사전 학습된 모델을 특정 task에 적용하기 위해 fine-tuning 하는 방식으로 task를 위한 구조의 필요성을 제거하였습니다.
    
* * *

트랜스포머 기반 전이 학습 모델들이 상당한 성능 향상을 이루었지만, 여전히 task를 위한 데이터셋과 fine-tuning 과정이 필요하다는 단점이 있습니다.

특정 task에서 강력한 성능을 내기 위해서는 일반적으로 수천, 수십만개의 데이터를 이용하여 fine-tuning을 해야합니다.

이러한 과정이 필요하지 않다면 이상적일 것이라는 다양한 이유가 있습니다.

- 실용적인 관점에서 task를 위해 라벨링된 대규모 데이터셋의 필요성은 언어 모델의 적용성을 제한합니다.

  너무 많은 종류의 task가 존재하고, 모든 task에 대해 대규모 데이터셋을 수집하는 것은 쉬운 일이 아닙니다.
  
- 학습 데이터에서 거짓된 상관 관계를 악용할 가능성은 기본적으로 모델의 표현력과 훈련 분포의 좁음과 함께 커집니다.

  넓은 범위의 정보를 흡수하는 사전 학습 과정 후, 특정 task를 위한 좁은 범위로 미세 조정하는 것은 문제를 발생시킬 수 있습니다.
  
- 실제로 사람은 대부분의 언어 task를 학습하는데 많은 데이터를 필요로 하지 않습니다.

  사람은 간략한 지시나 적은 예시만으로 언어 task를 수행할 수 있습니다.
  
  이러한 적응성은 사람이 다양한 task와 skill을 섞거나 교차하여 수행할 수 있도록 합니다.
  
  논문에서는 NLP 시스템을 넓은 범위에 활용할 수 있도록 이러한 유동성과 일반성을 갖기를 바랍니다.

* * *

이러한 문제를 해결하기 위한 방식에는 **meta-learning**이 있습니다.

<img src="/assets/img/GPT-3/fig1.1.JPG" width="100%" height="100%">

```
비지도 사전 학습 동안에는 언어 모델이 넓은 범위의 능력을 발달시키고, 추론 시 이러한 능력을 원하는 task로 적용시킵니다.

각 시퀀스로 forward-pass 하는 과정을 inner loop 라고 부르고, 전체 시퀀스로 사전 학습하는 과정을 outer loop 라고 부릅니다.

그림과 같이 단일 시퀀스 내에는 반복적인 sub-task가 포함되어 있습니다.

```

# Approach











  
  
  
  





  





  
  
  
  




